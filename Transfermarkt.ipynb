{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfermarkt.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RAAgf8Ctlvx"
      },
      "source": [
        "from matplotlib import pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras import metrics\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras import activations\r\n",
        "from tensorflow.keras import callbacks\r\n",
        "from tensorflow.keras import models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmouIwch32Nx"
      },
      "source": [
        "cols = pd.read_csv(\"data.csv\", nrows = 0).columns.tolist()\r\n",
        "remove_cols = [0, 1, 2, 4, 5, 6, 9, 10, 13, 19, 20, 22, 23, 24, 25, 26, 27, 88]\r\n",
        "cats = [\"Work Rate\", \"Position\"]\r\n",
        "for i in range(28, 54):\r\n",
        "    remove_cols.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziPeZ5A2385h"
      },
      "source": [
        "def currency_to_number(np_array):\r\n",
        "    np_array = np_array.str.replace(\"€\", \"\")\r\n",
        "    np_array = np_array.replace({'K': '*1e3', 'M': '*1e6'}, \r\n",
        "                                regex=True).map(pd.eval).astype(float)\r\n",
        "    return np_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "BM_nV9xt366I",
        "outputId": "c4567884-2c4a-4077-ac29-d85d60fecc5e"
      },
      "source": [
        "def create_df(file_name):\r\n",
        "    _df = pd.read_csv(file_name, delim_whitespace=False, names=cols, skiprows=1)\r\n",
        "    names = _df[\"Name\"]\r\n",
        "    _df.drop(_df.columns[remove_cols],axis=1,inplace=True)\r\n",
        "    _df[\"Preferred Foot\"].replace(\"Left\", 1, inplace=True)\r\n",
        "    _df[\"Preferred Foot\"].replace(\"Right\", 0, inplace=True)\r\n",
        "    _df = pd.get_dummies(_df, prefix=cats, columns=cats)\r\n",
        "    _df[\"Value\"] = currency_to_number(_df[\"Value\"])\r\n",
        "    _df[\"Wage\"] = currency_to_number(_df[\"Wage\"])\r\n",
        "    return _df, names\r\n",
        "\r\n",
        "df, _ = create_df(\"data.csv\")\r\n",
        "mins = {}\r\n",
        "maxs = {}\r\n",
        "for a in df.columns:\r\n",
        "    if a not in cats:\r\n",
        "        mins[a] = df[a].min()\r\n",
        "        maxs[a] = df[a].max()\r\n",
        "\r\n",
        "def scale_data(_df):\r\n",
        "    for a in _df.columns:\r\n",
        "        if a not in cats:\r\n",
        "            _df[a] = (_df[a] - mins[a]) / (maxs[a] - mins[a])\r\n",
        "    return _df\r\n",
        "\r\n",
        "df = scale_data(df)\r\n",
        "corr_matrix = df.corr()\r\n",
        "drop_cols = []\r\n",
        "for i in range(0, len(corr_matrix[\"Value\"])):\r\n",
        "    if abs(corr_matrix[\"Value\"][i]) < 0.15 and \"GK\" not in df.columns[i]:\r\n",
        "        drop_cols.append(i)\r\n",
        "    if \"GK\" in df.columns[i]:\r\n",
        "        df[df.columns[i]] = df[df.columns[i]] * df[\"Position_GK\"]\r\n",
        "df = df.drop(df.columns[drop_cols], axis=1).fillna(0)\r\n",
        "df[df < 0] = 0\r\n",
        "df[df > 1] = 1\r\n",
        "\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Overall</th>\n",
              "      <th>Potential</th>\n",
              "      <th>Value</th>\n",
              "      <th>Wage</th>\n",
              "      <th>International Reputation</th>\n",
              "      <th>Weak Foot</th>\n",
              "      <th>Skill Moves</th>\n",
              "      <th>Crossing</th>\n",
              "      <th>Finishing</th>\n",
              "      <th>HeadingAccuracy</th>\n",
              "      <th>ShortPassing</th>\n",
              "      <th>Volleys</th>\n",
              "      <th>Dribbling</th>\n",
              "      <th>Curve</th>\n",
              "      <th>FKAccuracy</th>\n",
              "      <th>LongPassing</th>\n",
              "      <th>BallControl</th>\n",
              "      <th>Acceleration</th>\n",
              "      <th>SprintSpeed</th>\n",
              "      <th>Agility</th>\n",
              "      <th>Reactions</th>\n",
              "      <th>ShotPower</th>\n",
              "      <th>Stamina</th>\n",
              "      <th>LongShots</th>\n",
              "      <th>Aggression</th>\n",
              "      <th>Positioning</th>\n",
              "      <th>Vision</th>\n",
              "      <th>Penalties</th>\n",
              "      <th>Composure</th>\n",
              "      <th>GKDiving</th>\n",
              "      <th>GKHandling</th>\n",
              "      <th>GKKicking</th>\n",
              "      <th>GKPositioning</th>\n",
              "      <th>GKReflexes</th>\n",
              "      <th>Position_GK</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.978723</td>\n",
              "      <td>0.932489</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.897727</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.965116</td>\n",
              "      <td>0.953488</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.988636</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.929412</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.939024</td>\n",
              "      <td>0.986667</td>\n",
              "      <td>0.892473</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.440476</td>\n",
              "      <td>0.989247</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.804598</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.978723</td>\n",
              "      <td>0.649789</td>\n",
              "      <td>0.716814</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.897727</td>\n",
              "      <td>0.989247</td>\n",
              "      <td>0.944444</td>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.965116</td>\n",
              "      <td>0.903226</td>\n",
              "      <td>0.852273</td>\n",
              "      <td>0.802198</td>\n",
              "      <td>0.809524</td>\n",
              "      <td>0.978022</td>\n",
              "      <td>0.905882</td>\n",
              "      <td>0.940476</td>\n",
              "      <td>0.890244</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.904762</td>\n",
              "      <td>0.989011</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.919540</td>\n",
              "      <td>0.989247</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.958333</td>\n",
              "      <td>0.957447</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.513274</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.840909</td>\n",
              "      <td>0.913978</td>\n",
              "      <td>0.644444</td>\n",
              "      <td>0.895349</td>\n",
              "      <td>0.930233</td>\n",
              "      <td>0.989247</td>\n",
              "      <td>0.931818</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.821429</td>\n",
              "      <td>0.989011</td>\n",
              "      <td>0.964706</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.973333</td>\n",
              "      <td>0.838710</td>\n",
              "      <td>0.821429</td>\n",
              "      <td>0.868132</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.935484</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.873563</td>\n",
              "      <td>0.978495</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.957447</td>\n",
              "      <td>0.607595</td>\n",
              "      <td>0.460177</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.118280</td>\n",
              "      <td>0.188889</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.104651</td>\n",
              "      <td>0.150538</td>\n",
              "      <td>0.170455</td>\n",
              "      <td>0.175824</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.406593</td>\n",
              "      <td>0.529412</td>\n",
              "      <td>0.547619</td>\n",
              "      <td>0.560976</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>0.311828</td>\n",
              "      <td>0.369048</td>\n",
              "      <td>0.098901</td>\n",
              "      <td>0.321429</td>\n",
              "      <td>0.107527</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.402299</td>\n",
              "      <td>0.698925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.955556</td>\n",
              "      <td>0.977528</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.936170</td>\n",
              "      <td>0.860759</td>\n",
              "      <td>0.628319</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.860215</td>\n",
              "      <td>0.566667</td>\n",
              "      <td>0.988372</td>\n",
              "      <td>0.906977</td>\n",
              "      <td>0.881720</td>\n",
              "      <td>0.897727</td>\n",
              "      <td>0.879121</td>\n",
              "      <td>0.976190</td>\n",
              "      <td>0.945055</td>\n",
              "      <td>0.776471</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.792683</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.956989</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.967033</td>\n",
              "      <td>0.773810</td>\n",
              "      <td>0.913978</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.850575</td>\n",
              "      <td>0.913978</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18202</th>\n",
              "      <td>0.020833</td>\n",
              "      <td>0.361702</td>\n",
              "      <td>0.000506</td>\n",
              "      <td>0.001770</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.329545</td>\n",
              "      <td>0.387097</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.488372</td>\n",
              "      <td>0.244186</td>\n",
              "      <td>0.408602</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.340659</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.417582</td>\n",
              "      <td>0.494118</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.560976</td>\n",
              "      <td>0.373333</td>\n",
              "      <td>0.440860</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.384615</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.397849</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.436782</td>\n",
              "      <td>0.451613</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18203</th>\n",
              "      <td>0.020833</td>\n",
              "      <td>0.319149</td>\n",
              "      <td>0.000506</td>\n",
              "      <td>0.001770</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.204545</td>\n",
              "      <td>0.537634</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.418605</td>\n",
              "      <td>0.372093</td>\n",
              "      <td>0.376344</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>0.186813</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.384615</td>\n",
              "      <td>0.341176</td>\n",
              "      <td>0.321429</td>\n",
              "      <td>0.292683</td>\n",
              "      <td>0.253333</td>\n",
              "      <td>0.419355</td>\n",
              "      <td>0.369048</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.473118</td>\n",
              "      <td>0.273810</td>\n",
              "      <td>0.436782</td>\n",
              "      <td>0.419355</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18204</th>\n",
              "      <td>0.020833</td>\n",
              "      <td>0.404255</td>\n",
              "      <td>0.000506</td>\n",
              "      <td>0.001770</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.227273</td>\n",
              "      <td>0.408602</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.360465</td>\n",
              "      <td>0.395349</td>\n",
              "      <td>0.440860</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.263736</td>\n",
              "      <td>0.226190</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.682353</td>\n",
              "      <td>0.678571</td>\n",
              "      <td>0.439024</td>\n",
              "      <td>0.346667</td>\n",
              "      <td>0.462366</td>\n",
              "      <td>0.511905</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.494624</td>\n",
              "      <td>0.392857</td>\n",
              "      <td>0.574713</td>\n",
              "      <td>0.408602</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18205</th>\n",
              "      <td>0.020833</td>\n",
              "      <td>0.382979</td>\n",
              "      <td>0.000506</td>\n",
              "      <td>0.001770</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.443182</td>\n",
              "      <td>0.516129</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.406977</td>\n",
              "      <td>0.418605</td>\n",
              "      <td>0.505376</td>\n",
              "      <td>0.318182</td>\n",
              "      <td>0.318681</td>\n",
              "      <td>0.273810</td>\n",
              "      <td>0.516484</td>\n",
              "      <td>0.576471</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.463415</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.340659</td>\n",
              "      <td>0.261905</td>\n",
              "      <td>0.451613</td>\n",
              "      <td>0.440476</td>\n",
              "      <td>0.517241</td>\n",
              "      <td>0.462366</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18206</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.382979</td>\n",
              "      <td>0.000506</td>\n",
              "      <td>0.001770</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.409091</td>\n",
              "      <td>0.344086</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.476744</td>\n",
              "      <td>0.302326</td>\n",
              "      <td>0.419355</td>\n",
              "      <td>0.386364</td>\n",
              "      <td>0.340659</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.505495</td>\n",
              "      <td>0.529412</td>\n",
              "      <td>0.511905</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.440860</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.318681</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.344086</td>\n",
              "      <td>0.464286</td>\n",
              "      <td>0.321839</td>\n",
              "      <td>0.430108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18207 rows × 35 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Overall  Potential     Value  ...  GKPositioning  GKReflexes  Position_GK\n",
              "0      1.000000   0.978723  0.932489  ...       0.000000         0.0          0.0\n",
              "1      1.000000   0.978723  0.649789  ...       0.000000         0.0          0.0\n",
              "2      0.958333   0.957447  1.000000  ...       0.000000         0.0          0.0\n",
              "3      0.937500   0.957447  0.607595  ...       0.977528         1.0          1.0\n",
              "4      0.937500   0.936170  0.860759  ...       0.000000         0.0          0.0\n",
              "...         ...        ...       ...  ...            ...         ...          ...\n",
              "18202  0.020833   0.361702  0.000506  ...       0.000000         0.0          0.0\n",
              "18203  0.020833   0.319149  0.000506  ...       0.000000         0.0          0.0\n",
              "18204  0.020833   0.404255  0.000506  ...       0.000000         0.0          0.0\n",
              "18205  0.020833   0.382979  0.000506  ...       0.000000         0.0          0.0\n",
              "18206  0.000000   0.382979  0.000506  ...       0.000000         0.0          0.0\n",
              "\n",
              "[18207 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWR-gVt24FsM",
        "outputId": "404af0ff-3ad7-4bfb-a531-8592e8e7463b"
      },
      "source": [
        "y = df[\"Value\"]\r\n",
        "X = df.drop(columns=[\"Value\"])\r\n",
        "xtrain, xvaltest, ytrain, yvaltest = train_test_split(X, y, test_size=0.3)\r\n",
        "xval, xtest, yval, ytest = train_test_split(xvaltest, yvaltest, test_size=0.5)\r\n",
        "\r\n",
        "weight_neuron = []\r\n",
        "\r\n",
        "train_len = len(xtrain)\r\n",
        "test_len = len(xtest)\r\n",
        "y_len = len(ytrain)\r\n",
        "\r\n",
        "class CustomCallback(callbacks.Callback):\r\n",
        "    def on_train_batch_end(self, batch, logs=None):\r\n",
        "        temp = self.model.layers[2].get_weights()[0].tolist()\r\n",
        "        weight_neuron.append(temp)\r\n",
        "\r\n",
        "model = models.Sequential()\r\n",
        "model.add(Dense(85,activation=\"sigmoid\",input_dim=34))\r\n",
        "model.add(Dense(50,activation=\"sigmoid\"))\r\n",
        "model.add(Dense(1,activation=\"sigmoid\"))\r\n",
        "\r\n",
        "model.compile(optimizer=\"adam\",\r\n",
        "            loss=\"mean_squared_error\")\r\n",
        "\r\n",
        "weight_neuron = []\r\n",
        "\r\n",
        "history_train = model.fit(xtrain, ytrain,\r\n",
        "                batch_size=32, epochs=100,\r\n",
        "                validation_data=(xval, yval),\r\n",
        "                callbacks=[CustomCallback()],\r\n",
        "                )\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0042 - val_loss: 0.0020\n",
            "Epoch 2/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0023 - val_loss: 0.0020\n",
            "Epoch 3/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0022 - val_loss: 0.0019\n",
            "Epoch 4/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0020 - val_loss: 0.0016\n",
            "Epoch 5/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - val_loss: 9.4483e-04\n",
            "Epoch 6/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 8.8214e-04 - val_loss: 5.2757e-04\n",
            "Epoch 7/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 6.6745e-04 - val_loss: 4.7189e-04\n",
            "Epoch 8/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 6.0006e-04 - val_loss: 4.2721e-04\n",
            "Epoch 9/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 5.4073e-04 - val_loss: 4.0016e-04\n",
            "Epoch 10/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 4.8987e-04 - val_loss: 3.7431e-04\n",
            "Epoch 11/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 4.2917e-04 - val_loss: 3.6378e-04\n",
            "Epoch 12/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 4.0542e-04 - val_loss: 3.0220e-04\n",
            "Epoch 13/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 3.6591e-04 - val_loss: 2.8626e-04\n",
            "Epoch 14/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 3.3484e-04 - val_loss: 2.8714e-04\n",
            "Epoch 15/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 2.9577e-04 - val_loss: 2.4286e-04\n",
            "Epoch 16/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 2.7181e-04 - val_loss: 2.1030e-04\n",
            "Epoch 17/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 2.5500e-04 - val_loss: 2.4576e-04\n",
            "Epoch 18/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 2.4322e-04 - val_loss: 2.2690e-04\n",
            "Epoch 19/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 2.2976e-04 - val_loss: 1.7672e-04\n",
            "Epoch 20/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 2.2749e-04 - val_loss: 2.0092e-04\n",
            "Epoch 21/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 2.0147e-04 - val_loss: 1.5160e-04\n",
            "Epoch 22/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.9750e-04 - val_loss: 1.5031e-04\n",
            "Epoch 23/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.8283e-04 - val_loss: 1.5021e-04\n",
            "Epoch 24/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.9434e-04 - val_loss: 1.4856e-04\n",
            "Epoch 25/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.8314e-04 - val_loss: 2.0884e-04\n",
            "Epoch 26/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.7869e-04 - val_loss: 1.4352e-04\n",
            "Epoch 27/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.7321e-04 - val_loss: 1.7647e-04\n",
            "Epoch 28/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.7130e-04 - val_loss: 1.7796e-04\n",
            "Epoch 29/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.7011e-04 - val_loss: 1.9228e-04\n",
            "Epoch 30/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.6798e-04 - val_loss: 1.3600e-04\n",
            "Epoch 31/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.6564e-04 - val_loss: 1.2032e-04\n",
            "Epoch 32/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.6491e-04 - val_loss: 1.5327e-04\n",
            "Epoch 33/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.6009e-04 - val_loss: 1.4832e-04\n",
            "Epoch 34/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.6178e-04 - val_loss: 1.2825e-04\n",
            "Epoch 35/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.6016e-04 - val_loss: 2.0821e-04\n",
            "Epoch 36/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.5641e-04 - val_loss: 1.1577e-04\n",
            "Epoch 37/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.4561e-04 - val_loss: 1.2228e-04\n",
            "Epoch 38/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.5179e-04 - val_loss: 1.1266e-04\n",
            "Epoch 39/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.4860e-04 - val_loss: 1.1246e-04\n",
            "Epoch 40/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.4639e-04 - val_loss: 1.1186e-04\n",
            "Epoch 41/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.4342e-04 - val_loss: 1.9425e-04\n",
            "Epoch 42/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.4063e-04 - val_loss: 1.1596e-04\n",
            "Epoch 43/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.4350e-04 - val_loss: 1.1799e-04\n",
            "Epoch 44/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.4771e-04 - val_loss: 1.0896e-04\n",
            "Epoch 45/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.3061e-04 - val_loss: 1.1182e-04\n",
            "Epoch 46/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.4542e-04 - val_loss: 1.1595e-04\n",
            "Epoch 47/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.3355e-04 - val_loss: 1.2937e-04\n",
            "Epoch 48/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.3124e-04 - val_loss: 1.2615e-04\n",
            "Epoch 49/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.3152e-04 - val_loss: 1.1133e-04\n",
            "Epoch 50/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.2862e-04 - val_loss: 1.0463e-04\n",
            "Epoch 51/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.4446e-04 - val_loss: 1.0904e-04\n",
            "Epoch 52/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.2488e-04 - val_loss: 1.0196e-04\n",
            "Epoch 53/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.3470e-04 - val_loss: 1.3748e-04\n",
            "Epoch 54/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.3691e-04 - val_loss: 1.0429e-04\n",
            "Epoch 55/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.3059e-04 - val_loss: 1.0555e-04\n",
            "Epoch 56/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.2778e-04 - val_loss: 1.0611e-04\n",
            "Epoch 57/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.1848e-04 - val_loss: 1.0269e-04\n",
            "Epoch 58/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.2356e-04 - val_loss: 9.7967e-05\n",
            "Epoch 59/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.2439e-04 - val_loss: 1.0202e-04\n",
            "Epoch 60/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.2310e-04 - val_loss: 1.7017e-04\n",
            "Epoch 61/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.2180e-04 - val_loss: 9.4527e-05\n",
            "Epoch 62/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.1775e-04 - val_loss: 1.0279e-04\n",
            "Epoch 63/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.2395e-04 - val_loss: 1.1368e-04\n",
            "Epoch 64/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.1644e-04 - val_loss: 1.0344e-04\n",
            "Epoch 65/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.1477e-04 - val_loss: 1.2387e-04\n",
            "Epoch 66/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.1356e-04 - val_loss: 1.0222e-04\n",
            "Epoch 67/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.1684e-04 - val_loss: 1.0721e-04\n",
            "Epoch 68/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.1459e-04 - val_loss: 9.7168e-05\n",
            "Epoch 69/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.0652e-04 - val_loss: 1.6800e-04\n",
            "Epoch 70/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.2627e-04 - val_loss: 1.0531e-04\n",
            "Epoch 71/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.1203e-04 - val_loss: 1.0629e-04\n",
            "Epoch 72/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.2055e-04 - val_loss: 1.1735e-04\n",
            "Epoch 73/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.0689e-04 - val_loss: 1.6492e-04\n",
            "Epoch 74/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.0895e-04 - val_loss: 1.1959e-04\n",
            "Epoch 75/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.0450e-04 - val_loss: 1.0922e-04\n",
            "Epoch 76/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.0494e-04 - val_loss: 1.0925e-04\n",
            "Epoch 77/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.1271e-04 - val_loss: 1.3899e-04\n",
            "Epoch 78/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.1230e-04 - val_loss: 1.1663e-04\n",
            "Epoch 79/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.1669e-04 - val_loss: 1.0753e-04\n",
            "Epoch 80/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.1339e-04 - val_loss: 1.3829e-04\n",
            "Epoch 81/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.0652e-04 - val_loss: 1.3586e-04\n",
            "Epoch 82/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.0105e-04 - val_loss: 9.8541e-05\n",
            "Epoch 83/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 9.8738e-05 - val_loss: 1.1671e-04\n",
            "Epoch 84/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.0073e-04 - val_loss: 1.3495e-04\n",
            "Epoch 85/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.0238e-04 - val_loss: 1.4054e-04\n",
            "Epoch 86/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 9.8645e-05 - val_loss: 1.4209e-04\n",
            "Epoch 87/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 1.1899e-04 - val_loss: 3.0629e-04\n",
            "Epoch 88/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 9.9487e-05 - val_loss: 1.2632e-04\n",
            "Epoch 89/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 9.3579e-05 - val_loss: 1.0672e-04\n",
            "Epoch 90/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 9.8529e-05 - val_loss: 1.0583e-04\n",
            "Epoch 91/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 9.9392e-05 - val_loss: 9.8726e-05\n",
            "Epoch 92/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 9.9020e-05 - val_loss: 1.0529e-04\n",
            "Epoch 93/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 9.1925e-05 - val_loss: 1.0413e-04\n",
            "Epoch 94/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 9.9940e-05 - val_loss: 1.4896e-04\n",
            "Epoch 95/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 9.9280e-05 - val_loss: 1.6172e-04\n",
            "Epoch 96/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 9.3439e-05 - val_loss: 1.0760e-04\n",
            "Epoch 97/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 9.3184e-05 - val_loss: 1.1130e-04\n",
            "Epoch 98/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 9.8121e-05 - val_loss: 1.3122e-04\n",
            "Epoch 99/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 9.2848e-05 - val_loss: 1.0610e-04\n",
            "Epoch 100/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 9.0193e-05 - val_loss: 1.2052e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eES74fdt7kTs",
        "outputId": "ed679aa3-489a-43ba-d017-6d1f391fa99a"
      },
      "source": [
        "new_df, names = create_df(\"test_data.csv\")\r\n",
        "new_df = scale_data(new_df)\r\n",
        "for col in new_df.columns:\r\n",
        "    if col not in X.columns:\r\n",
        "        new_df.drop(columns=[col], inplace=True)\r\n",
        "for i in range(0, len(X.columns)):\r\n",
        "    if X.columns[i] not in new_df.columns:\r\n",
        "        index = new_df.index\r\n",
        "        number_of_rows = len(index)\r\n",
        "        new_df.insert(i, X.columns[i], np.zeros(number_of_rows))\r\n",
        "\r\n",
        "predictions = model.predict(new_df)\r\n",
        "for i in range(0, len(predictions)):\r\n",
        "    val = (predictions[i] * (maxs[\"Value\"] - mins[\"Value\"])) + mins[\"Value\"]\r\n",
        "    prefix = \"\"\r\n",
        "    if val > 1000000:\r\n",
        "        prefix = \"M\"\r\n",
        "        val = val / 1000000\r\n",
        "    elif val > 1000:\r\n",
        "        prefix = \"K\"\r\n",
        "        val = val / 1000\r\n",
        "    print(names[i] + \" is worth €\" + str(val[0].round(2)) + prefix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A is worth €20.86M\n",
            "B is worth €58.29M\n",
            "C is worth €29.17M\n",
            "D is worth €12.29M\n",
            "E is worth €79.68M\n",
            "F is worth €4.87M\n",
            "G is worth €45.65M\n",
            "H is worth €65.8M\n",
            "I is worth €51.25K\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}